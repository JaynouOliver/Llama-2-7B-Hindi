{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba56e50-cafe-4c6c-8a2f-e7ec5e99fb03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data already aligned\n",
      "corpus already aligned\n",
      "Mapping tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4532830/4532830 [00:05<00:00, 783953.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens with a translation: 128256\n",
      "Number of new tokens: 128256\n",
      "Percentage of tokens with a translation: 100.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128256/128256 [00:00<00:00, 1622876.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the source model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b464065d707949cdaed7a9c3f089faa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20436992f9db4121b9e408c97af892d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91164e886d546af93f5f83f586f64a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc66b1aa40e540528f11328361f5c7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852b914946e249ef9f59a5f4b2fb5e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380dfdc5eda549c2a8bccf39a6f88b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97936e0e84604c999feecb5ce0c8a1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03143c76e2a46c782b63f9fc2b13d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remapping the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128256/128256 [00:10<00:00, 12167.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-19 21:29:11,021] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('en-hi-llama3-8b/tokenizer_config.json',\n",
       " 'en-hi-llama3-8b/special_tokens_map.json',\n",
       " 'en-hi-llama3-8b/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from project import create_aligned_corpus, align, map_tokens, smooth_mapping, remap_model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "\n",
    "source_model = \"meta-llama/Meta-Llama-3-8B\"\n",
    "\n",
    "target_tokenizer = \"meta-llama/Meta-Llama-3-8B\"\n",
    "export_dir = \"en-hi-llama3-8b\"\n",
    "\n",
    "corpus = create_aligned_corpus(\n",
    "    source_language=\"en\",\n",
    "    target_language=\"hi\",\n",
    "    source_tokenizer=source_model,\n",
    "    target_tokenizer=target_tokenizer,\n",
    ")\n",
    "\n",
    "mapped_tokens_file = align(corpus, fast_align_path=\"fast_align/build/fast_align\")\n",
    "\n",
    "tokenized_possible_translations, untokenized_possible_translations = map_tokens(mapped_tokens_file, source_model, target_tokenizer)\n",
    "\n",
    "smoothed_mapping = smooth_mapping(target_tokenizer, tokenized_possible_translations)\n",
    "\n",
    "model = remap_model(source_model, target_tokenizer, smoothed_mapping, source_model)\n",
    "os.makedirs(export_dir, exist_ok=False)\n",
    "new_tokenizer = AutoTokenizer.from_pretrained(target_tokenizer)\n",
    "model.save_pretrained(export_dir)\n",
    "new_tokenizer.save_pretrained(export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3de4c3e2-0c25-4844-82e1-a950be77d6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('en-hi-llama3-8b/tokenizer_config.json',\n",
       " 'en-hi-llama3-8b/special_tokens_map.json',\n",
       " 'en-hi-llama3-8b/tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.save(model.state_dict(), os.path.join(export_dir, \"pytorch_model.bin\"))\n",
    "model.config.save_pretrained(export_dir)\n",
    "new_tokenizer.save_pretrained(export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5702cf79-acb2-43ff-bddd-f6f7f61897a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69227e962d04a31be740afcd2286199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757ec303ca2a40c99c4dbdf3f0bb60de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)B-Hindi/model-00001-of-00007.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1b2a2767b0486eb8a329bb8dcafeca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)B-Hindi/model-00002-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84b74615d4743e39595bce9b52ba42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)B-Hindi/model-00003-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b38634452dc4dfdb8a1c821c2c50401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)B-Hindi/model-00004-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f6cca27eb543349727a163120564a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)B-Hindi/model-00005-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605d49d6d3fc473691ba0894024f8094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)B-Hindi/model-00006-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8831cf71f1704410b771d6f3c1ca40da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)B-Hindi/model-00007-of-00007.safetensors:   0%|          | 0.00/2.57G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95ea21c5d1a444eb32e3f662ba523be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)/Meta-Llama-3-8B-Hindi/pytorch_model.bin:   0%|          | 0.00/32.1G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/subhrokomol/en-hi-llama3-8b/commit/0ce6b5b6763db44c4308ffb94b5c826455aeef3e', commit_message='Upload folder using huggingface_hub', commit_description='', oid='0ce6b5b6763db44c4308ffb94b5c826455aeef3e', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push to Hugging Face Hub\n",
    "import huggingface_hub as hf_hub\n",
    "# basemodel_path = \"en-hi-llama3-8b\"\n",
    "# loramodel_path = \"danwils/mala-alpaca\"\n",
    "output_model_name = \"en-hi-llama3-8b\"\n",
    "# hf_token = \"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\"\n",
    "\n",
    "repo = hf_hub.create_repo(output_model_name, private=False)  # Set private=False if you want it to be public\n",
    "hf_hub.upload_folder(\n",
    "    folder_path=output_model_name,\n",
    "    path_in_repo='subhrokomol/Meta-Llama-3-8B-Hindi',  # Root of the repo\n",
    "    repo_id=f\"{hf_hub.whoami()['name']}/{output_model_name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c35c38-1bdb-4a02-852f-b3e19b173cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
