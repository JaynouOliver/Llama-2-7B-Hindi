{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [01:14<00:00, 24.93s/it]\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  1.93s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "import torch\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> You are an AI assistant specialized in explaining complex scientific concepts in simple terms.\n",
      "Explain quantum entanglement to a 10-year-old.\n",
      "Sure, let's imagine you have two magic dice that always show the same number when rolled at exactly the same time‚Äîno matter how far apart they are! This strange connection between them is called \"quantum entangling.\" It means their states become linked and can affect each other instantly no matter what distance separates them (even if it‚Äôs across galaxies). But here comes the tricky part: this doesn't work with regular objects like your toys or me; only tiny particles\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"You are an AI assistant specialized in explaining complex scientific concepts in simple terms.\n",
    "Explain quantum entanglement to a 10-year-old.\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Get the number of tokens in the prompt\n",
    "prompt_length = inputs.input_ids.shape[1]\n",
    "\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_length=prompt_length + 100,  # Prompt length plus 100 new tokens\n",
    "    min_new_tokens=1,  # Ensure at least one new token is generated\n",
    "    num_beams=1,\n",
    "    no_repeat_ngram_size=3,\n",
    "    repetition_penalty=1.5,\n",
    "    temperature=0.7,\n",
    "    top_p=0.92,\n",
    "    do_sample=True,\n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "# Decode only the new tokens\n",
    "model_response = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "# model_response = tokenizer.decode(output[0][prompt_length], skip_special_tokens=False) #gives only the output\n",
    "print(model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing json \n",
    "import json\n",
    "\n",
    "with open('Hindi_Benchmark_data.json', 'r', encoding='utf-8') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to get model response\n",
    "def get_model_response(question):\n",
    "    prompt = f\"<s>[INST] {question} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    prompt_length = inputs.input_ids.shape[1]\n",
    "    \n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_length=prompt_length + 100,\n",
    "        num_beams=1,\n",
    "        temperature=0.7,\n",
    "        top_p=0.92,\n",
    "        do_sample=True,\n",
    "        use_cache=True\n",
    "    )\n",
    "    \n",
    "    model_response = tokenizer.decode(output[0][prompt_length:], skip_special_tokens=False)\n",
    "    return model_response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def calculate_perplexity(question, answer):\n",
    "    inputs = tokenizer(question + \" \" + answer, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "    return torch.exp(outputs.loss).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:36<00:00, 12.29s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§Ö‡§ï‡§¨‡§∞ ‡§î‡§∞ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§è‡§ï ‡§¶‡§ø‡§® ‡§¨‡§ó‡•Ä‡§ö‡•á ‡§Æ‡•á‡§Ç ‡§ü‡§π‡§≤ ‡§∞‡§π‡•á ‡§•‡•á‡•§ ‡§Ö‡§ö‡§æ‡§®‡§ï ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§™‡•Ç‡§õ‡§æ, '‡§ï‡•ç‡§Ø‡§æ ‡§§‡•Å‡§Æ ‡§ú‡§æ‡§® ‡§∏‡§ï‡§§‡•á ‡§π‡•ã ‡§ï‡§ø ‡§Ü‡§ú ‡§Æ‡•á‡§∞‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ö‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à?' ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§§‡•Å‡§∞‡§Ç‡§§ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡§ø‡§Ø‡§æ, '‡§π‡§æ‡§Ç ‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú, ‡§Ü‡§™ ‡§á‡§∏ ‡§∏‡§Æ‡§Ø ‡§¨‡§ó‡•Ä‡§ö‡•á ‡§ï‡•Ä ‡§∏‡•Å‡§Ç‡§¶‡§∞‡§§‡§æ ‡§ï‡§æ ‡§Ü‡§®‡§Ç‡§¶ ‡§≤‡•á ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§' ‡§Ö‡§ï‡§¨‡§∞ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•Ä ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§®‡•Ä ‡§∏‡•á ‡§¨‡§π‡•Å‡§§ ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§ø‡§§ ‡§π‡•Å‡§è‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§Ö‡§ï‡§¨‡§∞ ‡§î‡§∞ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡§ø‡§∏ ‡§ú‡§ó‡§π ‡§ü‡§π‡§≤ ‡§∞‡§π‡•á ‡§•‡•á?\n",
      "Reference Answer: ‡§¨‡§ó‡•Ä‡§ö‡•á ‡§Æ‡•á‡§Ç\n",
      "Model Answer: ‡§Ö‡§ï‡§¨–∞—Ä ‡§î‡§∞ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§¨‡§ó‡•Ä‡§ö‡•á ‡§Æ‡•á‡§Ç ‡§ü‡§π‡§≤ ‡§∞‡§π‡•á ‡§•‡•á‡•§\n",
      "Perplexity: 2.6256015300750732\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§ï‡•á ‡§™‡§æ‡§∏ ‡§è‡§ï ‡§Ö‡§®‡•ã‡§ñ‡§æ ‡§§‡•ã‡§§‡§æ ‡§•‡§æ ‡§ú‡•ã ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•Ä ‡§®‡§ï‡§≤ ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§ï‡§∞‡§§‡§æ ‡§•‡§æ‡•§ ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§∞‡§æ‡§ú‡§æ ‡§®‡•á ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§∏‡•á ‡§™‡•Ç‡§õ‡§æ, '‡§ï‡•ç‡§Ø‡§æ ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡§æ ‡§§‡•ã‡§§‡§æ ‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§≤‡•á ‡§∏‡§ï‡§§‡§æ ‡§π‡•à?' ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§§‡•ã‡§§‡•á ‡§∏‡•á ‡§ï‡§π‡§æ, '‡§∞‡§æ‡§ú‡§æ ‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§≤‡•ã‡•§' ‡§§‡•ã‡§§‡•á ‡§®‡•á ‡§§‡•Å‡§∞‡§Ç‡§§ ‡§ï‡§π‡§æ, '‡§∞‡§æ‡§ú‡§æ ‡§ï‡•É‡§∑‡•ç‡§£‡§¶‡•á‡§µ ‡§∞‡§æ‡§Ø‡•§' ‡§∞‡§æ‡§ú‡§æ ‡§Ø‡§π ‡§∏‡•Å‡§®‡§ï‡§∞ ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂ ‡§π‡•Å‡§è‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§ï‡§æ ‡§§‡•ã‡§§‡§æ ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§•‡§æ?\n",
      "Reference Answer: ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•Ä ‡§®‡§ï‡§≤\n",
      "Model Answer: Tenali Ramakrishna's unique parrot could mimic people's voices very well.\n",
      "\n",
      "Answer: Tenali Ramakrishna's parrot could mimic people's voices.\n",
      "Perplexity: 2.556901693344116\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§ï‡§ø‡§∏ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§ï‡•ã ‡§™‡•Ç‡§∞‡§æ ‡§ï‡§∞‡•á‡§ó‡§æ? 2, 6, 12, 20, ___\n",
      "Reference Answer: 30\n",
      "Model Answer: 40 ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§ï‡•ã ‡§™‡•Ç‡§∞‡§æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à 2, 6, 12, 20, 40 ‡§ï‡§æ ‡§∏‡•á‡§§‡•Å. ‡§Ø‡§π ‡§è‡§ï ‡§î‡§∞ ‡§è‡§ï ‡§î‡§∞ ‡§è‡§ï ‡§Ö‡§∞‡•ç‡§•‡§æ‡§§‡•ç 2, 6, 12, 20,\n",
      "Perplexity: 2.719683885574341\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§è‡§ï ‡§ï‡§ø‡§∏‡§æ‡§® ‡§ï‡•á ‡§™‡§æ‡§∏ ‡§è‡§ï ‡§¨‡§ï‡§∞‡•Ä, ‡§è‡§ï ‡§ó‡§æ‡§ú‡§∞ ‡§î‡§∞ ‡§è‡§ï ‡§∂‡•á‡§∞ ‡§•‡§æ‡•§ ‡§â‡§∏‡•á ‡§®‡§¶‡•Ä ‡§™‡§æ‡§∞ ‡§ï‡§∞‡§®‡•Ä ‡§•‡•Ä ‡§≤‡•á‡§ï‡§ø‡§® ‡§®‡§æ‡§µ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§ï‡•á‡§µ‡§≤ ‡§è‡§ï ‡§π‡•Ä ‡§ö‡•Ä‡§ú ‡§≤‡•á ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§•‡§æ‡•§ ‡§Ø‡§¶‡§ø ‡§µ‡§π ‡§¨‡§ï‡§∞‡•Ä ‡§î‡§∞ ‡§ó‡§æ‡§ú‡§∞ ‡§ï‡•ã ‡§∏‡§æ‡§• ‡§õ‡•ã‡§°‡§º‡§§‡§æ ‡§π‡•à, ‡§§‡•ã ‡§¨‡§ï‡§∞‡•Ä ‡§ó‡§æ‡§ú‡§∞ ‡§ñ‡§æ ‡§ú‡§æ‡§è‡§ó‡•Ä‡•§ ‡§Ø‡§¶‡§ø ‡§µ‡§π ‡§∂‡•á‡§∞ ‡§î‡§∞ ‡§¨‡§ï‡§∞‡•Ä ‡§ï‡•ã ‡§∏‡§æ‡§• ‡§õ‡•ã‡§°‡§º‡§§‡§æ ‡§π‡•à, ‡§§‡•ã ‡§∂‡•á‡§∞ ‡§¨‡§ï‡§∞‡•Ä ‡§ñ‡§æ ‡§ú‡§æ‡§è‡§ó‡§æ‡•§ ‡§ï‡§ø‡§∏‡§æ‡§® ‡§ï‡•à‡§∏‡•á ‡§∏‡§≠‡•Ä ‡§ï‡•ã ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§®‡§¶‡•Ä ‡§™‡§æ‡§∞ ‡§ï‡§∞‡§æ‡§è‡§ó‡§æ?\n",
      "Reference Answer: ‡§™‡§π‡§≤‡•á ‡§¨‡§ï‡§∞‡•Ä ‡§ï‡•ã ‡§™‡§æ‡§∞ ‡§≤‡•á ‡§ú‡§æ‡§è, ‡§´‡§ø‡§∞ ‡§ó‡§æ‡§ú‡§∞ ‡§ï‡•ã ‡§≤‡•á ‡§ú‡§æ‡§è ‡§î‡§∞ ‡§¨‡§ï‡§∞‡•Ä ‡§ï‡•ã ‡§µ‡§æ‡§™‡§∏ ‡§≤‡§æ‡§è‡•§ ‡§Ö‡§¨ ‡§∂‡•á‡§∞ ‡§ï‡•ã ‡§™‡§æ‡§∞ ‡§≤‡•á ‡§ú‡§æ‡§è ‡§î‡§∞ ‡§´‡§ø‡§∞ ‡§¨‡§ï‡§∞‡•Ä ‡§ï‡•ã ‡§µ‡§æ‡§™‡§∏ ‡§≤‡§æ‡§è‡•§ ‡§Ö‡§Ç‡§§ ‡§Æ‡•á‡§Ç, ‡§¨‡§ï‡§∞‡•Ä ‡§ï‡•ã ‡§™‡•Å‡§®‡§É ‡§™‡§æ‡§∞ ‡§≤‡•á ‡§ú‡§æ‡§è‡•§\n",
      "Model Answer: ‡§â‡§∏ ‡§ï‡§ø‡§∏‡§æ‡§® ‡§®‡•á ‡§¨‡§ï‡§∞‡•Ä ‡§î‡§∞ ‡§ó‡§æ‡§ú‡§∞ ‡§ï‡•ã ‡§¨‡§ø‡§®‡§æ ‡§Ö‡§≤‡§ó ‡§≤‡•á ‡§ï‡§∞ ‡§¶‡•ã ‡§®‡§¶‡•Ä ‡§ï‡•á ‡§¶‡•ã ‡§ì‡§∞ ‡§∏‡•á ‡§ö‡§≤‡§æ ‡§¶‡§ø‡§Ø‡§æ‡•§ ‡§´‡§ø‡§∞ ‡§¨‡§ï‡§∞‡•Ä ‡§î‡§∞ ‡§ó‡§æ‡§ú‡§∞ ‡§ï‡•ã ‡§Ö\n",
      "Perplexity: 2.3577167987823486\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§™‡•Ç‡§õ‡§æ, '‡§¨‡•Ä‡§∞‡§¨‡§≤, ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§™‡§æ‡§∏ ‡§ï‡§ø‡§§‡§®‡§æ ‡§ú‡•ç‡§û‡§æ‡§® ‡§π‡•à?' ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡§ø‡§Ø‡§æ, '‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú, ‡§ú‡•ç‡§û‡§æ‡§® ‡§ï‡•Ä ‡§ï‡•ã‡§à ‡§∏‡•Ä‡§Æ‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã‡§§‡•Ä, ‡§Ø‡§π ‡§Ö‡§®‡§Ç‡§§ ‡§π‡•à‡•§' ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡§æ ‡§ú‡•ç‡§û‡§æ‡§® ‡§ï‡•à‡§∏‡§æ ‡§•‡§æ?\n",
      "Reference Answer: ‡§Ö‡§®‡§Ç‡§§\n",
      "Model Answer: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡§æ ‡§ú‡•ç‡§û‡§æ‡§® ‡§Ö‡§®‡§Ç‡§§ ‡§•‡§æ, ‡§ï‡•ç‡§Ø‡•ã‡§ï‡§ø ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§ï‡§π‡§æ ‡§•‡§æ ‡§ï‡§ø ‡§ú‡•ç‡§û‡§æ‡§® ‡§ï‡•Ä ‡§ï‡•ã‡§à ‡§∏‡•Ä‡§Æ‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã‡§§‡•Ä ‡§π‡•à‡•§\n",
      "Perplexity: 2.1273910999298096\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§™‡•Ç‡§õ‡§æ ‡§ï‡§ø ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡§æ ‡§∏‡§§‡•ç‡§Ø ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡§ø‡§Ø‡§æ, '‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú, ‡§∏‡§Æ‡§Ø ‡§π‡•Ä ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡§æ ‡§∏‡§§‡•ç‡§Ø ‡§π‡•à, ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π ‡§ï‡§ø‡§∏‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§π‡•Ä‡§Ç ‡§∞‡•Å‡§ï‡§§‡§æ‡•§' ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡§æ ‡§∏‡§§‡•ç‡§Ø ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?\n",
      "Reference Answer: ‡§∏‡§Æ‡§Ø\n",
      "Model Answer: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞, ‡§∏‡§Æ‡§Ø ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡§æ ‡§∏‡§§‡•ç‡§Ø ‡§π‡•à, ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π ‡§ï‡§ø‡§∏‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§π‡•Ä‡§Ç ‡§∞‡•Å‡§ï‡§§‡§æ‡•§ ‡§á‡§∏ ‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§ï‡•á ‡§Ö‡§∞‡•ç‡§• ‡§∏‡•á, ‡§∏‡§Æ‡§Ø\n",
      "Perplexity: 2.132641553878784\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§∏‡§π‡•Ä ‡§â‡§§‡•ç‡§§‡§∞ ‡§ö‡•Å‡§®‡•á‡§Ç: ‡§Ö‡§ï‡§¨‡§∞ ‡§ï‡§æ ‡§ú‡§®‡•ç‡§Æ ‡§ï‡§π‡§æ‡§Å ‡§π‡•Å‡§Ü ‡§•‡§æ? (‡§ï) ‡§Ü‡§ó‡§∞‡§æ (‡§ñ) ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä (‡§ó) ‡§ï‡§æ‡§¨‡•Å‡§≤ (‡§ò) ‡§Ö‡§ú‡§Æ‡•á‡§∞\n",
      "Reference Answer: ‡§Ö‡§ú‡§Æ‡•á‡§∞\n",
      "Model Answer: ‡§Ö‡§ï‡§¨‡§∞ ‡§ï‡§æ ‡§ú‡§®‡•ç‡§Æ ‡§ï‡§æ‡§¨‡•Å‡§≤ (‡§ò) ‡§Æ‡•á‡§Ç ‡§π‡•Å‡§Ü ‡§•‡§æ.\n",
      "Perplexity: 2.848371982574463\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§è‡§ï ‡§™‡•ç‡§∞‡§§‡§ø‡§Ø‡•ã‡§ó‡§ø‡§§‡§æ ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§ó ‡§≤‡§ø‡§Ø‡§æ ‡§ú‡§π‡§æ‡§Å ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§Ö‡§™‡§®‡•Ä ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§®‡•Ä ‡§ï‡§æ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§∞‡§®‡§æ ‡§•‡§æ‡•§ ‡§â‡§∏‡§®‡•á ‡§è‡§ï ‡§™‡§π‡•á‡§≤‡•Ä ‡§∏‡•Å‡§≤‡§ù‡§æ‡§à ‡§ú‡§ø‡§∏‡§∏‡•á ‡§∏‡§≠‡•Ä ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§ø‡§§ ‡§π‡•Å‡§è‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§ï‡§ø‡§∏ ‡§™‡•ç‡§∞‡§§‡§ø‡§Ø‡•ã‡§ó‡§ø‡§§‡§æ ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§ó ‡§≤‡§ø‡§Ø‡§æ?\n",
      "Reference Answer: ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§®‡•Ä ‡§ï‡•Ä ‡§™‡•ç‡§∞‡§§‡§ø‡§Ø‡•ã‡§ó‡§ø‡§§‡§æ\n",
      "Model Answer: Tenali Ram ‡§®‡•á ‡§ï‡§π‡§æ‡§Å ‡§™‡•ç‡§∞‡§§‡§ø‡§Ø‡•ã‡§ó‡§ø‡§§‡§æ ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§ó ‡§≤‡§ø‡§Ø‡§æ ‡§â‡§∏‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§ ‡§Ø‡§π ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§ï‡•á ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è\n",
      "Perplexity: 2.463453531265259\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•ã ‡§∏‡§æ‡§¨‡§ø‡§§ ‡§ï‡§∞‡§®‡§æ ‡§•‡§æ ‡§ï‡§ø ‡§â‡§®‡§ï‡•á ‡§™‡§æ‡§∏ ‡§Ö‡§®‡•ã‡§ñ‡•Ä ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§®‡•Ä ‡§π‡•à‡•§ ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§è‡§ï ‡§Æ‡•Å‡§∂‡•ç‡§ï‡§ø‡§≤ ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ï‡§æ ‡§π‡§≤ ‡§®‡§ø‡§ï‡§æ‡§≤‡§ï‡§∞ ‡§∏‡§≠‡•Ä ‡§ï‡•ã ‡§ö‡•å‡§Ç‡§ï‡§æ ‡§¶‡§ø‡§Ø‡§æ‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§∏‡§æ‡§¨‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ?\n",
      "Reference Answer: ‡§ï‡§ø ‡§â‡§®‡§ï‡•á ‡§™‡§æ‡§∏ ‡§Ö‡§®‡•ã‡§ñ‡•Ä ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§®‡•Ä ‡§π‡•à\n",
      "Model Answer: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§∏‡§æ‡§¨‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ï‡§ø ‡§µ‡§π ‡§Ö‡§®‡•ã‡§ñ‡•Ä ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§® ‡§π‡•à‡•§ ‡§≤‡•á‡§ï‡§ø‡§® ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§ï‡§æ ‡§π‡§≤ ‡§¶‡•á‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•Å‡§õ ‡§Ö‡§ß‡§ø‡§ï ‡§ú‡§æ‡§µ‡§æ‡§¨ ‡§ö‡§æ‡§π‡§ø‡§è\n",
      "Perplexity: 2.3873822689056396\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§∏‡§π‡•Ä ‡§â‡§§‡•ç‡§§‡§∞ ‡§ö‡•Å‡§®‡•á‡§Ç: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§ï‡§æ ‡§™‡•Ç‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§ï‡•ç‡§Ø‡§æ ‡§•‡§æ? (‡§ï) ‡§§‡•á‡§®‡§æ‡§≤‡•Ä ‡§∞‡§æ‡§Æ‡§ï‡•É‡§∑‡•ç‡§£ (‡§ñ) ‡§§‡•á‡§®‡§æ‡§≤‡•Ä ‡§∞‡§æ‡§Æ‡•Ç (‡§ó) ‡§§‡•á‡§®‡§æ‡§≤‡•Ä ‡§∞‡§æ‡§Æ‡§æ‡§Ø‡§® (‡§ò) ‡§§‡•á‡§®‡§æ‡§≤‡•Ä ‡§∞‡§æ‡§Æ‡§∏‡•ç‡§µ‡§æ‡§Æ‡•Ä\n",
      "Reference Answer: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä ‡§∞‡§æ‡§Æ‡§ï‡•É‡§∑‡•ç‡§£\n",
      "Model Answer: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä ‡§∞‡§æ‡§Æ‡§ï‡•É‡§∑‡•ç‡§£ (‡§ï) ‡§•‡§æ‡•§\n",
      "Perplexity: 3.0049307346343994\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§™‡•Ç‡§õ‡§æ, '‡§¨‡•Ä‡§∞‡§¨‡§≤, ‡§Ø‡§¶‡§ø ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§™‡§æ‡§∏ ‡§§‡•Ä‡§® ‡§∏‡•á‡§¨ ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§§‡•Å‡§Æ‡•ç‡§π‡•á‡§Ç ‡§Æ‡•Å‡§ù‡•á ‡§è‡§ï ‡§¶‡•á‡§®‡§æ ‡§π‡•à, ‡§§‡•ã ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§™‡§æ‡§∏ ‡§ï‡§ø‡§§‡§®‡•á ‡§∏‡•á‡§¨ ‡§¨‡§ö‡•á‡§Ç‡§ó‡•á?' ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡§ø‡§Ø‡§æ, '‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú, ‡§Æ‡•á‡§∞‡•á ‡§™‡§æ‡§∏ ‡§§‡•Ä‡§® ‡§∏‡•á‡§¨ ‡§•‡•á, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Ü‡§™‡§®‡•á ‡§ï‡§π‡§æ ‡§ï‡§ø ‡§Æ‡•Å‡§ù‡•á ‡§è‡§ï ‡§¶‡•á‡§®‡§æ ‡§π‡•à, ‡§á‡§∏‡§ï‡§æ ‡§Æ‡§§‡§≤‡§¨ ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•á ‡§™‡§æ‡§∏ ‡§è‡§ï ‡§î‡§∞ ‡§Æ‡•á‡§∞‡•á ‡§™‡§æ‡§∏ ‡§¶‡•ã ‡§¨‡§ö‡•á‡§Ç‡§ó‡•á‡•§' ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§æ?\n",
      "Reference Answer: ‡§Ø‡§¶‡§ø ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§™‡§æ‡§∏ ‡§§‡•Ä‡§® ‡§∏‡•á‡§¨ ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§§‡•Å‡§Æ‡•ç‡§π‡•á‡§Ç ‡§Æ‡•Å‡§ù‡•á ‡§è‡§ï ‡§¶‡•á‡§®‡§æ ‡§π‡•à, ‡§§‡•ã ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§™‡§æ‡§∏ ‡§ï‡§ø‡§§‡§®‡•á ‡§∏‡•á‡§¨ ‡§¨‡§ö‡•á‡§Ç‡§ó‡•á?\n",
      "Model Answer: ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á '‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§™‡§æ‡§∏ ‡§§‡•Ä‡§® ‡§∏‡•á‡§¨ ‡§•‡•á, ‡§≤‡•á‡§ï‡§ø‡§® ‡§§‡•Å‡§Æ‡•ç‡§π‡•á‡§Ç ‡§Æ‡•Å‡§ù‡•á ‡§è‡§ï ‡§¶‡•á‡§®‡§æ ‡§π‡•à, ‡§§‡•ã ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§™‡§æ‡§∏ ‡§ï‡§ø‡§§‡§®‡•á ‡§∏‡•á\n",
      "Perplexity: 1.9435442686080933\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§è‡§ï ‡§¶‡§ø‡§® ‡§∞‡§æ‡§ú‡§æ ‡§ï‡•É‡§∑‡•ç‡§£‡§¶‡•á‡§µ ‡§∞‡§æ‡§Ø ‡§®‡•á ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§∏‡•á ‡§ï‡§π‡§æ ‡§ï‡§ø ‡§µ‡•á ‡§è‡§ï ‡§ê‡§∏‡•Ä ‡§ï‡§µ‡§ø‡§§‡§æ ‡§≤‡§ø‡§ñ‡•á‡§Ç ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§ï‡•á‡§µ‡§≤ ‡§§‡•Ä‡§® ‡§™‡§Ç‡§ï‡•ç‡§§‡§ø‡§Ø‡§æ‡§Å ‡§π‡•ã‡§Ç, ‡§≤‡•á‡§ï‡§ø‡§® ‡§â‡§∏‡§Æ‡•á‡§Ç ‡§ó‡§π‡§∞‡•Ä ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§®‡•Ä ‡§π‡•ã‡•§ ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§§‡•Å‡§∞‡§Ç‡§§ ‡§è‡§ï ‡§ï‡§µ‡§ø‡§§‡§æ ‡§¨‡§®‡§æ‡§à ‡§î‡§∞ ‡§∞‡§æ‡§ú‡§æ ‡§ï‡•ã ‡§∏‡•Å‡§®‡§æ‡§à‡•§ ‡§∞‡§æ‡§ú‡§æ ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂ ‡§π‡•Å‡§è‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§∞‡§æ‡§ú‡§æ ‡§®‡•á ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§≤‡§ø‡§ñ‡§®‡•á ‡§ï‡•ã ‡§ï‡§π‡§æ?\n",
      "Reference Answer: ‡§§‡•Ä‡§® ‡§™‡§Ç‡§ï‡•ç‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§µ‡§æ‡§≤‡•Ä ‡§ó‡§π‡§∞‡•Ä ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§®‡•Ä ‡§ï‡•Ä ‡§ï‡§µ‡§ø‡§§‡§æ\n",
      "Model Answer: ‡§™‡•ç‡§∞‡§§‡§ø‡§ú‡•ç‡§û‡§æ ‡§ï‡§ø ‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è ‡§ï‡§µ‡§ø‡§§‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§π‡•Ä ‡§ú‡§µ‡§æ‡§¨ ‡§π‡•à:\n",
      "\n",
      "1.\n",
      "\n",
      "‡§µ‡§π ‡§§‡§∞‡§π ‡§π‡•à ‡§ú‡§ø‡§∏‡§ï‡§æ ‡§∏‡•ç‡§•‡§æ‡§® ‡§Æ‡•á‡§∞‡•á ‡§¶‡§ø‡§≤ ‡§Æ‡•á‡§Ç ‡§π‡•à,\n",
      "‡§µ‡§π\n",
      "Perplexity: 2.5603272914886475\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§™‡•Ç‡§õ‡§æ ‡§ï‡§ø ‡§∏‡§Ç‡§∏‡§æ‡§∞ ‡§ï‡•Ä ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡§ø‡§Ø‡§æ, '‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú, ‡§™‡•ç‡§∞‡•á‡§Æ ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø ‡§π‡•à ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π ‡§∏‡§≠‡•Ä ‡§ï‡•ã ‡§ú‡•ã‡§°‡§º ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§' ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§∏‡§Ç‡§∏‡§æ‡§∞ ‡§ï‡•Ä ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?\n",
      "Reference Answer: ‡§™‡•ç‡§∞‡•á‡§Æ\n",
      "Model Answer: ‡§Ö‡§®‡•Å‡§§‡•ç‡§§‡§∞: ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Æ‡•Å‡§ù‡•á ‡§∏‡•á ‡§è‡§ï ‡§∏‡§æ‡§• ‡§´‡§∞‡•ç‡§Æ‡•á‡§ü ‡§ï‡•ã ‡§¶‡§ø‡§ú‡§ø‡§Ø‡•á, ‡§ï‡§ø ‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡•á ‡§¨‡•ã‡§§ ‡§ï‡•ã ‡§´‡•â‡§∞‡•ç‡§Æ‡•á‡§ü ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§∞‡§ñ\n",
      "Perplexity: 2.459002733230591\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§è‡§ï ‡§¶‡§ø‡§® ‡§¨‡§æ‡§ú‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Ç‡§Æ ‡§∞‡§π‡•á ‡§•‡•á, ‡§ú‡§¨ ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¶‡•á‡§ñ‡§æ ‡§ï‡§ø ‡§è‡§ï ‡§Ü‡§¶‡§Æ‡•Ä ‡§ù‡•Ç‡§† ‡§¨‡•ã‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à‡•§ ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§â‡§∏ ‡§Ü‡§¶‡§Æ‡•Ä ‡§∏‡•á ‡§ï‡§π‡§æ, '‡§∏‡§§‡•ç‡§Ø ‡§¨‡•ã‡§≤‡§®‡§æ ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§®‡•à‡§§‡§ø‡§ï‡§§‡§æ ‡§π‡•à‡•§' ‡§Ü‡§¶‡§Æ‡•Ä ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§ó‡§≤‡§§‡•Ä ‡§ï‡§æ ‡§è‡§π‡§∏‡§æ‡§∏ ‡§π‡•Å‡§Ü ‡§î‡§∞ ‡§â‡§∏‡§®‡•á ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§∏‡•á ‡§Æ‡§æ‡§´‡•Ä ‡§Æ‡§æ‡§Å‡§ó‡•Ä‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§Ü‡§¶‡§Æ‡•Ä ‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§π‡§æ?\n",
      "Reference Answer: ‡§∏‡§§‡•ç‡§Ø ‡§¨‡•ã‡§≤‡§®‡§æ ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§®‡•à‡§§‡§ø‡§ï‡§§‡§æ ‡§π‡•à\n",
      "Model Answer: Tenaaliram ne us adam se kaha, \"Satya bolna sabse baraati naitikta hai.\" (Translation: Tenaaliram said, \"Telling the truth is the greatest virtue.\")\n",
      "Perplexity: 2.3191986083984375\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§ï‡§π‡§æ ‡§ï‡§ø ‡§µ‡•á ‡§è‡§ï ‡§ê‡§∏‡§æ ‡§§‡§∞‡•Ä‡§ï‡§æ ‡§¨‡§§‡§æ‡§è‡§Ç ‡§ú‡§ø‡§∏‡§∏‡•á ‡§∏‡§≠‡•Ä ‡§≤‡•ã‡§ó ‡§ñ‡•Å‡§∂ ‡§π‡•ã ‡§∏‡§ï‡•á‡§Ç‡•§ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡§ø‡§Ø‡§æ, '‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú, ‡§∏‡§¨‡§ï‡•ã ‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§î‡§∞ ‡§∏‡§Æ‡§æ‡§®‡§§‡§æ ‡§¶‡•Ä‡§ú‡§ø‡§è, ‡§§‡§≠‡•Ä ‡§∏‡§≠‡•Ä ‡§≤‡•ã‡§ó ‡§ñ‡•Å‡§∂ ‡§π‡•ã ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§' ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§Ö‡§ï‡§¨‡§∞ ‡§ï‡•ã ‡§ï‡•ç‡§Ø‡§æ ‡§§‡§∞‡•Ä‡§ï‡§æ ‡§¨‡§§‡§æ‡§Ø‡§æ?\n",
      "Reference Answer: ‡§∏‡§¨‡§ï‡•ã ‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§î‡§∞ ‡§∏‡§Æ‡§æ‡§®‡§§‡§æ ‡§¶‡•á‡§®‡§æ\n",
      "Model Answer: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§Ö‡§ï‡§¨‡§∞ ‡§ï‡•ã ‡§â‡§∏ ‡§§‡§∞‡•Ä‡§ï‡§æ ‡§¨‡§§‡§æ‡§Ø‡§æ ‡§ï‡§ø ‡§∏‡§≠‡•Ä ‡§≤‡•ã‡§ó ‡§ñ‡•Å‡§∂ ‡§π‡•ã ‡§∏‡§ï‡•á‡§Ç, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú (‡§µ‡§ø‡§¶‡•á‡§∂ ‡§î‡§∞ ‡§∏‡§∞‡§ï‡§æ‡§∞) ‡§∏‡§¨‡§ï‡•ã ‡§®‡•ç‡§Ø‡§æ‡§Ø ÔøΩ\n",
      "Perplexity: 2.400193929672241\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§Ö‡§™‡§®‡•á ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§ï‡•ã ‡§è‡§ï ‡§Ö‡§®‡•ã‡§ñ‡•Ä ‡§ò‡§°‡§º‡•Ä ‡§¶‡•Ä ‡§ú‡•ã ‡§π‡§∞ ‡§ò‡§Ç‡§ü‡•á ‡§Ö‡§≤‡§ó-‡§Ö‡§≤‡§ó ‡§∞‡§Ç‡§ó ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡§§‡•Ä ‡§•‡•Ä‡•§ ‡§â‡§∏‡§ï‡•á ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§ï‡•ã ‡§Ø‡§π ‡§ò‡§°‡§º‡•Ä ‡§¨‡§π‡•Å‡§§ ‡§™‡§∏‡§Ç‡§¶ ‡§Ü‡§à ‡§î‡§∞ ‡§â‡§∏‡§®‡•á ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§ï‡•ã ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶ ‡§¶‡§ø‡§Ø‡§æ‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§Ö‡§™‡§®‡•á ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§ï‡•ã ‡§ï‡•ç‡§Ø‡§æ ‡§¶‡§ø‡§Ø‡§æ?\n",
      "Reference Answer: ‡§Ö‡§®‡•ã‡§ñ‡•Ä ‡§ò‡§°‡§º‡•Ä\n",
      "Model Answer: Tenaliraman ‡§®‡•á ‡§Ö‡§™‡§®‡•á ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§ï‡•ã ‡§â‡§∏ ‡§Ö‡§®‡•ã‡§ñ‡•Ä ‡§ò‡§°‡§º‡•Ä ‡§¶‡§ø‡§Ø‡§æ, ‡§ú‡•ã ‡§π‡§∞ ‡§ò‡§Ç‡§ü‡•á ‡§Ö‡§≤‡§ó-‡§Ö‡§≤‡§ó ‡§∞‡§Ç‡§ó ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡§§‡•Ä ‡§•‡•Ä‡•§\n",
      "Perplexity: 2.236809015274048\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§ï‡§π‡§æ ‡§ï‡§ø ‡§µ‡•á ‡§è‡§ï ‡§ê‡§∏‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•Ç‡§õ‡•á‡§Ç ‡§ú‡§ø‡§∏‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞ ‡§ï‡•ã‡§à ‡§® ‡§¶‡•á ‡§∏‡§ï‡•á‡•§ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§™‡•Ç‡§õ‡§æ, '‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú, ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§¨‡§§‡§æ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§á‡§∏ ‡§∏‡§Æ‡§Ø ‡§Ü‡§™‡§ï‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ö‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à?' ‡§Ö‡§ï‡§¨‡§∞ ‡§Æ‡•Å‡§∏‡•ç‡§ï‡•Å‡§∞‡§æ ‡§¶‡§ø‡§è ‡§î‡§∞ ‡§¨‡•ã‡§≤‡•á, '‡§¨‡•Ä‡§∞‡§¨‡§≤, ‡§§‡•Å‡§Æ‡§®‡•á ‡§Æ‡•Å‡§ù‡•á ‡§∏‡•ã‡§ö‡§®‡•á ‡§™‡§∞ ‡§Æ‡§ú‡§¨‡•Ç‡§∞ ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ‡•§' ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§Ö‡§ï‡§¨‡§∞ ‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§æ?\n",
      "Reference Answer: ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§¨‡§§‡§æ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§á‡§∏ ‡§∏‡§Æ‡§Ø ‡§Ü‡§™‡§ï‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ö‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à?\n",
      "Model Answer: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§Ö‡§ï‡§¨‡§∞ ‡§∏‡•á ‡§™‡•Ç‡§õ‡§æ ‡§ï‡§ø '‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™‡§ï‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ö‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à?' ‡§π‡•à.\n",
      "Perplexity: 2.343766927719116\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§Ö‡§™‡§®‡•á ‡§∞‡§æ‡§ú‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§≠‡•ã‡§ú ‡§ï‡§æ ‡§Ü‡§Ø‡•ã‡§ú‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§π‡§∞ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§∏‡•ç‡§µ‡§æ‡§¶‡§ø‡§∑‡•ç‡§ü ‡§µ‡•ç‡§Ø‡§Ç‡§ú‡§® ‡§™‡§∞‡•ã‡§∏‡•á‡•§ ‡§∞‡§æ‡§ú‡§æ ‡§®‡•á ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§ï‡•Ä ‡§™‡•ç‡§∞‡§∂‡§Ç‡§∏‡§æ ‡§ï‡•Ä ‡§î‡§∞ ‡§ï‡§π‡§æ ‡§ï‡§ø ‡§Ø‡§π ‡§â‡§®‡§ï‡•á ‡§ú‡•Ä‡§µ‡§® ‡§ï‡§æ ‡§∏‡§¨‡§∏‡•á ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§≠‡•ã‡§ú ‡§•‡§æ‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§∞‡§æ‡§ú‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§Ø‡•ã‡§ú‡§® ‡§ï‡§ø‡§Ø‡§æ?\n",
      "Reference Answer: ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§≠‡•ã‡§ú\n",
      "Model Answer: Tenaliraman ‡§®‡•á ‡§∞‡§æ‡§ú‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§≠‡•ã‡§ú ‡§ï‡§æ ‡§Ü‡§Ø‡•ã‡§ú‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§π‡§∞ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§∏‡•ç‡§µ‡§æ‡§¶‡§ø‡§∑‡•ç‡§ü ‡§µ‡•ç‡§Ø‡§Ç‡§ú‡§® ‡§™‡§∞‡•ã‡§∏‡•á (‡§â\n",
      "Perplexity: 2.1416046619415283\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§™‡•Ç‡§õ‡§æ ‡§ï‡§ø ‡§∏‡§¨‡§∏‡•á ‡§ï‡•Ä‡§Æ‡§§‡•Ä ‡§µ‡§∏‡•ç‡§§‡•Å ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡§ø‡§Ø‡§æ, '‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú, ‡§∏‡§¨‡§∏‡•á ‡§ï‡•Ä‡§Æ‡§§‡•Ä ‡§µ‡§∏‡•ç‡§§‡•Å ‡§∏‡§Æ‡§Ø ‡§π‡•à ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π ‡§ï‡§≠‡•Ä ‡§µ‡§æ‡§™‡§∏ ‡§®‡§π‡•Ä‡§Ç ‡§Ü‡§§‡§æ‡•§' ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§∏‡§¨‡§∏‡•á ‡§ï‡•Ä‡§Æ‡§§‡•Ä ‡§µ‡§∏‡•ç‡§§‡•Å ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?\n",
      "Reference Answer: ‡§∏‡§Æ‡§Ø\n",
      "Model Answer: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞, ‡§∏‡§¨‡§∏‡•á ‡§ï‡•Ä‡§Æ‡§§‡•Ä ‡§µ‡§∏‡•ç‡§§‡•Å ‡§∏‡§Æ‡§Ø ‡§π‡•à, ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π ‡§ï‡§≠‡•Ä ‡§µ‡§æ‡§™‡§∏ ‡§®‡§π‡•Ä‡§Ç ‡§Ü‡§§‡§æ‡•§\n",
      "Perplexity: 2.1306121349334717\n",
      "---\n",
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§è‡§ï ‡§¶‡§ø‡§® ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§¶‡•á‡§ñ‡§æ ‡§ï‡§ø ‡§è‡§ï ‡§ó‡§∞‡•Ä‡§¨ ‡§Ü‡§¶‡§Æ‡•Ä ‡§≠‡•Ç‡§ñ‡§æ ‡§π‡•à‡•§ ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§â‡§∏ ‡§Ü‡§¶‡§Æ‡•Ä ‡§ï‡•ã ‡§≠‡•ã‡§ú‡§® ‡§ï‡§∞‡§æ‡§Ø‡§æ ‡§î‡§∞ ‡§â‡§∏‡•á ‡§Ö‡§™‡§®‡•Ä ‡§ï‡•Å‡§õ ‡§ß‡§®‡§∞‡§æ‡§∂‡§ø ‡§≠‡•Ä ‡§¶‡•Ä‡•§ ‡§µ‡§π ‡§Ü‡§¶‡§Æ‡•Ä ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§ï‡§æ ‡§Ü‡§≠‡§æ‡§∞‡•Ä ‡§π‡•ã ‡§ó‡§Ø‡§æ ‡§î‡§∞ ‡§â‡§∏‡§®‡•á ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§ï‡•ã ‡§Ü‡§∂‡•Ä‡§∞‡•ç‡§µ‡§æ‡§¶ ‡§¶‡§ø‡§Ø‡§æ‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§â‡§∏ ‡§ó‡§∞‡•Ä‡§¨ ‡§Ü‡§¶‡§Æ‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§ø‡§Ø‡§æ?\n",
      "Reference Answer: ‡§≠‡•ã‡§ú‡§® ‡§ï‡§∞‡§æ‡§Ø‡§æ ‡§î‡§∞ ‡§ß‡§®‡§∞‡§æ‡§∂‡§ø ‡§¶‡•Ä\n",
      "Model Answer: Tenali Ram ‡§®‡•á ‡§â‡§∏ ‡§ó‡§∞‡•Ä‡§¨ ‡§Ü‡§¶‡§Æ‡•Ä ‡§ï‡•ã ‡§≠‡•ã‡§ú‡§® ‡§¶‡§ø‡§Ø‡§æ ‡§î‡§∞ ‡§â‡§∏‡•á ‡§Ö‡§™‡§®‡•Ä ‡§ï‡•Å‡§õ ‡§ß‡§®‡§∞‡§æ‡§∂‡§ø ‡§≠‡•Ä ‡§¶‡•Ä‡•§\n",
      "Perplexity: 2.283085584640503\n",
      "---\n",
      "Overall Perplexity Score: 2.3886796119444584\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load Mistral model and tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "def get_model_response(question):\n",
    "    prompt = f\"<s>[INST] {question} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    prompt_length = inputs.input_ids.shape[1]\n",
    "    \n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_length=prompt_length + 100,\n",
    "        num_beams=1,\n",
    "        temperature=0.7,\n",
    "        top_p=0.92,\n",
    "        do_sample=True,\n",
    "        use_cache=True\n",
    "    )\n",
    "    \n",
    "    model_response = tokenizer.decode(output[0][prompt_length:], skip_special_tokens=True)\n",
    "    return model_response.strip()\n",
    "\n",
    "def calculate_perplexity(question, answer):\n",
    "    inputs = tokenizer(question + \" \" + answer, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "    return torch.exp(outputs.loss).item()\n",
    "\n",
    "# Load the dataset\n",
    "with open('Hindi_Benchmark_data.json', 'r', encoding='utf-8') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "perplexities = []\n",
    "\n",
    "# Process only the first 20 questions\n",
    "for item in dataset[:20]:\n",
    "    question = item[\"Question\"]\n",
    "    reference_answer = item[\"Answer\"]\n",
    "    \n",
    "    model_answer = get_model_response(question)\n",
    "    \n",
    "    perplexity = calculate_perplexity(question, model_answer)\n",
    "    perplexities.append(perplexity)\n",
    "    \n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Reference Answer: {reference_answer}\")\n",
    "    print(f\"Model Answer: {model_answer}\")\n",
    "    print(f\"Perplexity: {perplexity}\")\n",
    "    print(\"---\")\n",
    "\n",
    "# Calculate the overall perplexity score\n",
    "overall_perplexity = np.exp(np.mean(np.log(perplexities)))\n",
    "\n",
    "print(f\"Overall Perplexity Score: {overall_perplexity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying with LORA model transtokenized + Finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: BNB_CUDA_VERSION=118 environment variable detected; loading libbitsandbytes_cuda118.so.\n",
      "This can be used to load a bitsandbytes version that is different from the PyTorch CUDA version.\n",
      "If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=\n",
      "If you use the manual override make sure the right libcudart.so is in your LD_LIBRARY_PATH\n",
      "For example by adding the following to your .bashrc: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:<path_to_cuda_dir/lib64\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"<s> Below is a conversation between a human and an AI assistant. Write a response that appropriately continues the conversation.\\n\\n### Conversation:\\nWhat is a famous tall tower in Paris?\\n\\n### Assistant:\\nThe Eiffel Tower is a famous tall tower in Paris. It's one of the most recognizable landmarks in the world.\\n\\n### Human:\\nHow tall is it?\\n\\n### Assistant:\\nThe Eiffel Tower stands at approximately 330 meters (1,08\"]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "#code to load the LORA model and run it.\n",
    "\n",
    "# Load the model\n",
    "if False:\n",
    "    from unsloth import FastLanguageModel\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"subhrokomol/Mistral-7B-Instruct-v0.3-transtokenized\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "    )\n",
    "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "# alpaca_prompt = \"\"\"Below is a conversation between a human and an AI assistant. Write a response that appropriately continues the conversation.\n",
    "\n",
    "# ### Conversation:\n",
    "# {}\n",
    "\n",
    "# ### Assistant:\"\"\"\n",
    "\n",
    "# inputs = tokenizer(\n",
    "# [\n",
    "#     alpaca_prompt.format(\n",
    "#         \"What is a famous tall tower in Paris?\", # instruction\n",
    "#         \"\", # input\n",
    "#         \"\", # output - leave this blank for generation!\n",
    "#     ),\n",
    "# ], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "# outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
    "# tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_response(question):\n",
    "    # Format the prompt\n",
    "    prompt = f\"<s>[INST] {question} [/INST]\"\n",
    "    \n",
    "    # Tokenize and generate\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True)\n",
    "    \n",
    "    # Decode and clean up the response\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract only the model's response\n",
    "    response = full_response.split(\"[INST]\")[-1].split(\"[/INST]\")[-1].strip()\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§ï‡§ø‡§∏ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§ï‡•ã ‡§™‡•Ç‡§∞‡§æ ‡§ï‡§∞‡•á‡§ó‡§æ? 2, 6, 12, 20, ___\n",
      "Answer: ‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§ï‡§ø‡§∏ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§ï‡•ã ‡§™‡•Ç‡§∞‡§æ ‡§ï‡§∞‡•á‡§ó‡§æ? 2, 6, 12, 20, ___  30 ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§ï‡•ã ‡§™‡•Ç‡§∞‡§æ ‡§ï‡§∞‡•á‡§ó‡§æ‡•§ ‡§Ø‡§π ‡§∏‡§∞‡§≤ ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§π‡•à, ‡§úisme ‡§∏‡§¨‡§∏‡•á ‡§™‡§π‡§≤‡•á\n"
     ]
    }
   ],
   "source": [
    "question = \"‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§ï‡§ø‡§∏ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§ï‡•ã ‡§™‡•Ç‡§∞‡§æ ‡§ï‡§∞‡•á‡§ó‡§æ? 2, 6, 12, 20, ___\"\n",
    "answer = get_model_response(question)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§Ö‡§ï‡§¨‡§∞ ‡§î‡§∞ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§è‡§ï ‡§¶‡§ø‡§® ‡§¨‡§ó‡•Ä‡§ö‡•á ‡§Æ‡•á‡§Ç ‡§ü‡§π‡§≤ ‡§∞‡§π‡•á ‡§•‡•á‡•§ ‡§Ö‡§ö‡§æ‡§®‡§ï ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§™‡•Ç‡§õ‡§æ, '‡§ï‡•ç‡§Ø‡§æ ‡§§‡•Å‡§Æ ‡§ú‡§æ‡§® ‡§∏‡§ï‡§§‡•á ‡§π‡•ã ‡§ï‡§ø ‡§Ü‡§ú ‡§Æ‡•á‡§∞‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ö‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à?' ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§§‡•Å‡§∞‡§Ç‡§§ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡§ø‡§Ø‡§æ, '‡§π‡§æ‡§Ç ‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú, ‡§Ü‡§™ ‡§á‡§∏ ‡§∏‡§Æ‡§Ø ‡§¨‡§ó‡•Ä‡§ö‡•á ‡§ï‡•Ä ‡§∏‡•Å‡§Ç‡§¶‡§∞‡§§‡§æ ‡§ï‡§æ ‡§Ü‡§®‡§Ç‡§¶ ‡§≤‡•á ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§' ‡§Ö‡§ï‡§¨‡§∞ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•Ä ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§®‡•Ä ‡§∏‡•á ‡§¨‡§π‡•Å‡§§ ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§ø‡§§ ‡§π‡•Å‡§è‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§Ö‡§ï‡§¨‡§∞ ‡§î‡§∞ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡§ø‡§∏ ‡§ú‡§ó‡§π ‡§ü‡§π‡§≤ ‡§∞‡§π‡•á ‡§•‡•á?\n",
      "Reference Answer: ‡§¨‡§ó‡•Ä‡§ö‡•á ‡§Æ‡•á‡§Ç\n",
      "Model Answer: ‡§Ö‡§ï‡§¨‡§∞ ‡§î‡§∞ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡§ø‡§∏ ‡§ú‡§ó‡§π ‡§ü‡§π‡§≤ ‡§∞‡§π‡•á ‡§•‡•á?  ‡§Ö‡§ï‡§¨–∞—Ä ‡§î‡§∞ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§¨‡§ó‡•Ä‡§ö‡•á ‡§Æ‡•á‡§Ç ‡§•‡•á‡•§\n",
      "Perplexity: 2.5458455085754395\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§ï‡•á ‡§™‡§æ‡§∏ ‡§è‡§ï ‡§Ö‡§®‡•ã‡§ñ‡§æ ‡§§‡•ã‡§§‡§æ ‡§•‡§æ ‡§ú‡•ã ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•Ä ‡§®‡§ï‡§≤ ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§ï‡§∞‡§§‡§æ ‡§•‡§æ‡•§ ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§∞‡§æ‡§ú‡§æ ‡§®‡•á ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§∏‡•á ‡§™‡•Ç‡§õ‡§æ, '‡§ï‡•ç‡§Ø‡§æ ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡§æ ‡§§‡•ã‡§§‡§æ ‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§≤‡•á ‡§∏‡§ï‡§§‡§æ ‡§π‡•à?' ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§§‡•ã‡§§‡•á ‡§∏‡•á ‡§ï‡§π‡§æ, '‡§∞‡§æ‡§ú‡§æ ‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§≤‡•ã‡•§' ‡§§‡•ã‡§§‡•á ‡§®‡•á ‡§§‡•Å‡§∞‡§Ç‡§§ ‡§ï‡§π‡§æ, '‡§∞‡§æ‡§ú‡§æ ‡§ï‡•É‡§∑‡•ç‡§£‡§¶‡•á‡§µ ‡§∞‡§æ‡§Ø‡•§' ‡§∞‡§æ‡§ú‡§æ ‡§Ø‡§π ‡§∏‡•Å‡§®‡§ï‡§∞ ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂ ‡§π‡•Å‡§è‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§ï‡§æ ‡§§‡•ã‡§§‡§æ ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§•‡§æ?\n",
      "Reference Answer: ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•Ä ‡§®‡§ï‡§≤\n",
      "Model Answer: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§ï‡§æ ‡§§‡•ã‡§§‡§æ ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§•‡§æ?  Tenali Raman ‡§ï‡§æ ‡§§‡•ã‡§§‡§æ ‡§∏‡•ã‡§®‡§æ ‡§•‡§æ, ‡§ú‡•ã ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•Ä ‡§®‡§ï‡§≤ ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§ï‡§∞‡§§‡§æ ‡§•‡§æ‡•§ ‡§á‡§∏ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡§ø ‡§ú‡§¨ ‡§∞‡§æ‡§ú‡§æ ‡§ï‡•É‡§∑‡•ç‡§£‡§¶‡•á‡§µ ‡§∞\n",
      "Perplexity: 2.334564685821533\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§ï‡§ø‡§∏ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§ï‡•ã ‡§™‡•Ç‡§∞‡§æ ‡§ï‡§∞‡•á‡§ó‡§æ? 2, 6, 12, 20, ___\n",
      "Reference Answer: 30\n",
      "Model Answer: ‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§ï‡§ø‡§∏ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§ï‡•ã ‡§™‡•Ç‡§∞‡§æ ‡§ï‡§∞‡•á‡§ó‡§æ? 2, 6, 12, 20, ___  40 ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§ï‡•ã ‡§™‡•Ç‡§∞‡§æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à 2, 6, 12, 20, 40 ‡§ï‡•á ‡§∏‡§æ‡§•‡•§ ‡§Ø‡§π ‡§Ö‡§∞‡•ç‡§•‡§æ‡§§ ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§™‡§π‡§≤‡•á 3 ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤\n",
      "Perplexity: 2.0721652507781982\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§è‡§ï ‡§ï‡§ø‡§∏‡§æ‡§® ‡§ï‡•á ‡§™‡§æ‡§∏ ‡§è‡§ï ‡§¨‡§ï‡§∞‡•Ä, ‡§è‡§ï ‡§ó‡§æ‡§ú‡§∞ ‡§î‡§∞ ‡§è‡§ï ‡§∂‡•á‡§∞ ‡§•‡§æ‡•§ ‡§â‡§∏‡•á ‡§®‡§¶‡•Ä ‡§™‡§æ‡§∞ ‡§ï‡§∞‡§®‡•Ä ‡§•‡•Ä ‡§≤‡•á‡§ï‡§ø‡§® ‡§®‡§æ‡§µ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§ï‡•á‡§µ‡§≤ ‡§è‡§ï ‡§π‡•Ä ‡§ö‡•Ä‡§ú ‡§≤‡•á ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§•‡§æ‡•§ ‡§Ø‡§¶‡§ø ‡§µ‡§π ‡§¨‡§ï‡§∞‡•Ä ‡§î‡§∞ ‡§ó‡§æ‡§ú‡§∞ ‡§ï‡•ã ‡§∏‡§æ‡§• ‡§õ‡•ã‡§°‡§º‡§§‡§æ ‡§π‡•à, ‡§§‡•ã ‡§¨‡§ï‡§∞‡•Ä ‡§ó‡§æ‡§ú‡§∞ ‡§ñ‡§æ ‡§ú‡§æ‡§è‡§ó‡•Ä‡•§ ‡§Ø‡§¶‡§ø ‡§µ‡§π ‡§∂‡•á‡§∞ ‡§î‡§∞ ‡§¨‡§ï‡§∞‡•Ä ‡§ï‡•ã ‡§∏‡§æ‡§• ‡§õ‡•ã‡§°‡§º‡§§‡§æ ‡§π‡•à, ‡§§‡•ã ‡§∂‡•á‡§∞ ‡§¨‡§ï‡§∞‡•Ä ‡§ñ‡§æ ‡§ú‡§æ‡§è‡§ó‡§æ‡•§ ‡§ï‡§ø‡§∏‡§æ‡§® ‡§ï‡•à‡§∏‡•á ‡§∏‡§≠‡•Ä ‡§ï‡•ã ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§®‡§¶‡•Ä ‡§™‡§æ‡§∞ ‡§ï‡§∞‡§æ‡§è‡§ó‡§æ?\n",
      "Reference Answer: ‡§™‡§π‡§≤‡•á ‡§¨‡§ï‡§∞‡•Ä ‡§ï‡•ã ‡§™‡§æ‡§∞ ‡§≤‡•á ‡§ú‡§æ‡§è, ‡§´‡§ø‡§∞ ‡§ó‡§æ‡§ú‡§∞ ‡§ï‡•ã ‡§≤‡•á ‡§ú‡§æ‡§è ‡§î‡§∞ ‡§¨‡§ï‡§∞‡•Ä ‡§ï‡•ã ‡§µ‡§æ‡§™‡§∏ ‡§≤‡§æ‡§è‡•§ ‡§Ö‡§¨ ‡§∂‡•á‡§∞ ‡§ï‡•ã ‡§™‡§æ‡§∞ ‡§≤‡•á ‡§ú‡§æ‡§è ‡§î‡§∞ ‡§´‡§ø‡§∞ ‡§¨‡§ï‡§∞‡•Ä ‡§ï‡•ã ‡§µ‡§æ‡§™‡§∏ ‡§≤‡§æ‡§è‡•§ ‡§Ö‡§Ç‡§§ ‡§Æ‡•á‡§Ç, ‡§¨‡§ï‡§∞‡•Ä ‡§ï‡•ã ‡§™‡•Å‡§®‡§É ‡§™‡§æ‡§∞ ‡§≤‡•á ‡§ú‡§æ‡§è‡•§\n",
      "Model Answer: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§è‡§ï ‡§ï‡§ø‡§∏‡§æ‡§® ‡§ï‡•á ‡§™‡§æ‡§∏ ‡§è‡§ï ‡§¨‡§ï‡§∞‡•Ä, ‡§è‡§ï ‡§ó‡§æ‡§ú‡§∞ ‡§î‡§∞ ‡§è‡§ï ‡§∂‡•á‡§∞ ‡§•‡§æ‡•§ ‡§â‡§∏‡•á ‡§®‡§¶‡•Ä ‡§™‡§æ‡§∞ ‡§ï‡§∞‡§®‡•Ä ‡§•‡•Ä ‡§≤‡•á‡§ï‡§ø‡§® ‡§®‡§æ‡§µ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§ï‡•á‡§µ‡§≤ ‡§è‡§ï ‡§π‡•Ä ‡§ö‡•Ä‡§ú ‡§≤‡•á ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§•‡§æ‡•§ ‡§Ø‡§¶‡§ø ‡§µ‡§π ‡§¨‡§ï‡§∞‡•Ä ‡§î‡§∞ ‡§ó‡§æ‡§ú‡§∞ ‡§ï‡•ã ‡§∏‡§æ‡§• ‡§õ‡•ã‡§°‡§º‡§§‡§æ ‡§π‡•à, ‡§§‡•ã ‡§¨‡§ï‡§∞‡•Ä ‡§ó‡§æ‡§ú‡§∞ ‡§ñ‡§æ ‡§ú‡§æ‡§è‡§ó‡•Ä‡•§ ‡§Ø‡§¶‡§ø ‡§µ‡§π ‡§∂‡•á‡§∞ ‡§î‡§∞ ‡§¨‡§ï‡§∞‡•Ä ‡§ï‡•ã ‡§∏‡§æ‡§• ‡§õ‡•ã‡§°‡§º‡§§‡§æ ‡§π‡•à, ‡§§‡•ã ‡§∂‡•á‡§∞ ‡§¨‡§ï‡§∞‡•Ä ‡§ñ‡§æ ‡§ú‡§æ‡§è‡§ó‡§æ‡•§ ‡§ï‡§ø‡§∏‡§æ‡§® ‡§ï‡•à‡§∏‡•á ‡§∏‡§≠‡•Ä ‡§ï‡•ã ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§®‡§¶‡•Ä ‡§™‡§æ‡§∞ ‡§ï‡§∞‡§æ‡§è‡§ó‡§æ?  ‡§ï‡§ø‡§∏‡§æ‡§® ‡§®‡•á ‡§¨‡§ï‡§∞‡•Ä ‡§î‡§∞ ‡§ó‡§æ‡§ú‡§∞ ‡§ï‡•ã ‡§è‡§ï ‡§¶‡•Ç‡§∏‡§∞‡•á ‡§∏‡•á ‡§¶‡•Ç‡§∞ ‡§∞‡§ñ‡§ï‡§∞ ‡§π‡•Ä ‡§®‡§¶‡•Ä ‡§™‡§æ‡§∞ ‡§ï‡§∞ ‡§≤‡§ø‡§Ø‡§æ ‡§•‡§æ, ‡§î‡§∞ ‡§∂‡•á‡§∞ ‡§ï‡•ã ‡§¨‡§æ‡§Å‡§ï‡•á ‡§™‡§∞ ‡§∞‡§ñ‡§æ ‡§•\n",
      "Perplexity: 1.6607437133789062\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§™‡•Ç‡§õ‡§æ, '‡§¨‡•Ä‡§∞‡§¨‡§≤, ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§™‡§æ‡§∏ ‡§ï‡§ø‡§§‡§®‡§æ ‡§ú‡•ç‡§û‡§æ‡§® ‡§π‡•à?' ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡§ø‡§Ø‡§æ, '‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú, ‡§ú‡•ç‡§û‡§æ‡§® ‡§ï‡•Ä ‡§ï‡•ã‡§à ‡§∏‡•Ä‡§Æ‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã‡§§‡•Ä, ‡§Ø‡§π ‡§Ö‡§®‡§Ç‡§§ ‡§π‡•à‡•§' ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡§æ ‡§ú‡•ç‡§û‡§æ‡§® ‡§ï‡•à‡§∏‡§æ ‡§•‡§æ?\n",
      "Reference Answer: ‡§Ö‡§®‡§Ç‡§§\n",
      "Model Answer: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡§æ ‡§ú‡•ç‡§û‡§æ‡§® ‡§ï‡•à‡§∏‡§æ ‡§•‡§æ?  ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§•‡§æ ‡§ï‡§ø '‡§ú‡•ç‡§û‡§æ‡§® ‡§ï‡•Ä ‡§ï‡•ã‡§à ‡§∏‡•Ä‡§Æ‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã‡§§‡•Ä, ‡§Ø‡§π ‡§Ö‡§®‡§Ç‡§§ ‡§π‡•à'. ‡§Ö‡§§‡•É‡§™‡•ç‡§§ ‡§∞‡§π‡§ï‡§∞ ‡§Ø‡§π ‡§™‡§§‡§æ ‡§ö‡§≤‡§æ ‡§ï\n",
      "Perplexity: 2.174736261367798\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§™‡•Ç‡§õ‡§æ ‡§ï‡§ø ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡§æ ‡§∏‡§§‡•ç‡§Ø ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡§ø‡§Ø‡§æ, '‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú, ‡§∏‡§Æ‡§Ø ‡§π‡•Ä ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡§æ ‡§∏‡§§‡•ç‡§Ø ‡§π‡•à, ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π ‡§ï‡§ø‡§∏‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§π‡•Ä‡§Ç ‡§∞‡•Å‡§ï‡§§‡§æ‡•§' ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡§æ ‡§∏‡§§‡•ç‡§Ø ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?\n",
      "Reference Answer: ‡§∏‡§Æ‡§Ø\n",
      "Model Answer: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡§æ ‡§∏‡§§‡•ç‡§Ø ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?  ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡§æ ‡§∏‡§§‡•ç‡§Ø ‡§π‡•à ‡§∏‡§Æ‡§Ø ‡§π‡•Ä ‡§π‡•à, ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§∏‡§Æ‡§Ø ‡§ï‡§ø‡§∏‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§π‡•Ä‡§Ç ‡§∞‡•Å‡§ï‡§§‡§æ‡•§\n",
      "Perplexity: 2.073301315307617\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§∏‡§π‡•Ä ‡§â‡§§‡•ç‡§§‡§∞ ‡§ö‡•Å‡§®‡•á‡§Ç: ‡§Ö‡§ï‡§¨‡§∞ ‡§ï‡§æ ‡§ú‡§®‡•ç‡§Æ ‡§ï‡§π‡§æ‡§Å ‡§π‡•Å‡§Ü ‡§•‡§æ? (‡§ï) ‡§Ü‡§ó‡§∞‡§æ (‡§ñ) ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä (‡§ó) ‡§ï‡§æ‡§¨‡•Å‡§≤ (‡§ò) ‡§Ö‡§ú‡§Æ‡•á‡§∞\n",
      "Reference Answer: ‡§Ö‡§ú‡§Æ‡•á‡§∞\n",
      "Model Answer: ‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§∏‡§π‡•Ä ‡§â‡§§‡•ç‡§§‡§∞ ‡§ö‡•Å‡§®‡•á‡§Ç: ‡§Ö‡§ï‡§¨‡§∞ ‡§ï‡§æ ‡§ú‡§®‡•ç‡§Æ ‡§ï‡§π‡§æ‡§Å ‡§π‡•Å‡§Ü ‡§•‡§æ? (‡§ï) ‡§Ü‡§ó‡§∞‡§æ (‡§ñ) ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä (‡§ó) ‡§ï‡§æ‡§¨‡•Å‡§≤ (‡§ò) ‡§Ö‡§ú‡§Æ‡•á‡§∞  ‡§Ö‡§ï‡§¨‡§∞ ‡§ï‡§æ ‡§ú‡§®‡•ç‡§Æ ‡§ï‡§æ‡§¨‡•Å‡§≤ (‡§ò) ‡§Æ‡•á‡§Ç ‡§π‡•Å‡§Ü ‡§•‡§æ‡•§\n",
      "Perplexity: 1.9295587539672852\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§è‡§ï ‡§™‡•ç‡§∞‡§§‡§ø‡§Ø‡•ã‡§ó‡§ø‡§§‡§æ ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§ó ‡§≤‡§ø‡§Ø‡§æ ‡§ú‡§π‡§æ‡§Å ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§Ö‡§™‡§®‡•Ä ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§®‡•Ä ‡§ï‡§æ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§∞‡§®‡§æ ‡§•‡§æ‡•§ ‡§â‡§∏‡§®‡•á ‡§è‡§ï ‡§™‡§π‡•á‡§≤‡•Ä ‡§∏‡•Å‡§≤‡§ù‡§æ‡§à ‡§ú‡§ø‡§∏‡§∏‡•á ‡§∏‡§≠‡•Ä ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§ø‡§§ ‡§π‡•Å‡§è‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§ï‡§ø‡§∏ ‡§™‡•ç‡§∞‡§§‡§ø‡§Ø‡•ã‡§ó‡§ø‡§§‡§æ ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§ó ‡§≤‡§ø‡§Ø‡§æ?\n",
      "Reference Answer: ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§®‡•Ä ‡§ï‡•Ä ‡§™‡•ç‡§∞‡§§‡§ø‡§Ø‡•ã‡§ó‡§ø‡§§‡§æ\n",
      "Model Answer: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§ï‡§ø‡§∏ ‡§™‡•ç‡§∞‡§§‡§ø‡§Ø‡•ã‡§ó‡§ø‡§§‡§æ ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§ó ‡§≤‡§ø‡§Ø‡§æ?  ‡§â‡§∏ ‡§ï‡§π‡§æ‡§®‡•Ä ‡§Æ‡•á‡§Ç Tenali Ram ‡§®‡•á ‡§ï‡§π‡§æ ‡§•‡§æ ‡§ï‡§ø ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§ï‡•ã‡§à ‡§™‡•ç‡§∞‡§§‡§ø‡§Ø‡•ã‡§ó‡§ø‡§§‡§æ ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§ó ‡§≤‡§ø‡§Ø‡§æ ‡§•‡§æ, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•à‡§Ç ‡§â‡§∏ ‡§™‡•ç‡§∞‡§§‡§ø‡§Ø‡•ã‡§ó‡§ø‡§§‡§æ ‡§ï‡§æ ‡§®\n",
      "Perplexity: 2.3090243339538574\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•ã ‡§∏‡§æ‡§¨‡§ø‡§§ ‡§ï‡§∞‡§®‡§æ ‡§•‡§æ ‡§ï‡§ø ‡§â‡§®‡§ï‡•á ‡§™‡§æ‡§∏ ‡§Ö‡§®‡•ã‡§ñ‡•Ä ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§®‡•Ä ‡§π‡•à‡•§ ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§è‡§ï ‡§Æ‡•Å‡§∂‡•ç‡§ï‡§ø‡§≤ ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ï‡§æ ‡§π‡§≤ ‡§®‡§ø‡§ï‡§æ‡§≤‡§ï‡§∞ ‡§∏‡§≠‡•Ä ‡§ï‡•ã ‡§ö‡•å‡§Ç‡§ï‡§æ ‡§¶‡§ø‡§Ø‡§æ‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§∏‡§æ‡§¨‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ?\n",
      "Reference Answer: ‡§ï‡§ø ‡§â‡§®‡§ï‡•á ‡§™‡§æ‡§∏ ‡§Ö‡§®‡•ã‡§ñ‡•Ä ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§®‡•Ä ‡§π‡•à\n",
      "Model Answer: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§∏‡§æ‡§¨‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ?  ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ ‡§ï‡§ø ‡§µ‡§π ‡§Ö‡§®‡•ã‡§ñ‡•Ä ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§® ‡§π‡•à‡•§ ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§è‡§ï ‡§Æ‡•Å‡§∂‡•ç‡§ï‡§ø‡§≤ ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ï‡§æ ‡§π‡§≤ ‡§®‡§ø‡§ï‡§æ‡§≤‡§ï‡§∞ ‡§∏‡§≠‡•Ä ‡§ï‡•ã ‡§ö‡•å‡§Ç‡§ï‡§æ\n",
      "Perplexity: 2.237152338027954\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§∏‡§π‡•Ä ‡§â‡§§‡•ç‡§§‡§∞ ‡§ö‡•Å‡§®‡•á‡§Ç: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§ï‡§æ ‡§™‡•Ç‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§ï‡•ç‡§Ø‡§æ ‡§•‡§æ? (‡§ï) ‡§§‡•á‡§®‡§æ‡§≤‡•Ä ‡§∞‡§æ‡§Æ‡§ï‡•É‡§∑‡•ç‡§£ (‡§ñ) ‡§§‡•á‡§®‡§æ‡§≤‡•Ä ‡§∞‡§æ‡§Æ‡•Ç (‡§ó) ‡§§‡•á‡§®‡§æ‡§≤‡•Ä ‡§∞‡§æ‡§Æ‡§æ‡§Ø‡§® (‡§ò) ‡§§‡•á‡§®‡§æ‡§≤‡•Ä ‡§∞‡§æ‡§Æ‡§∏‡•ç‡§µ‡§æ‡§Æ‡•Ä\n",
      "Reference Answer: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä ‡§∞‡§æ‡§Æ‡§ï‡•É‡§∑‡•ç‡§£\n",
      "Model Answer: ‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§∏‡§π‡•Ä ‡§â‡§§‡•ç‡§§‡§∞ ‡§ö‡•Å‡§®‡•á‡§Ç: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§ï‡§æ ‡§™‡•Ç‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§ï‡•ç‡§Ø‡§æ ‡§•‡§æ? (‡§ï) ‡§§‡•á‡§®‡§æ‡§≤‡•Ä ‡§∞‡§æ‡§Æ‡§ï‡•É‡§∑‡•ç‡§£ (‡§ñ) ‡§§‡•á‡§®‡§æ‡§≤‡•Ä ‡§∞‡§æ‡§Æ‡•Ç (‡§ó) ‡§§‡•á‡§®‡§æ‡§≤‡•Ä ‡§∞‡§æ‡§Æ‡§æ‡§Ø‡§® (‡§ò) ‡§§‡•á‡§®‡§æ‡§≤‡•Ä ‡§∞‡§æ‡§Æ‡§∏‡•ç‡§µ‡§æ‡§Æ‡•Ä  ‡§∏‡§π‡•Ä ‡§â‡§§‡•ç‡§§‡§∞ ‡§π‡•à (‡§ñ) ‡§§‡•á‡§®‡§æ‡§≤‡•Ä ‡§∞‡§æ‡§Æ‡•Ç (Tenali Ramakrishna) ‡§π‡•à‡•§ Tenali Ramakrishna ‡§ï‡§æ ‡§™‡•Ç‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§•‡§æ‡•§ ‡§µ‡§π ‡§è‡§ï ‡§î‡§∞‡§æ‡§ß ‡§π‡•à ‡§ú‡•ã 16 –≤–µ‡§ï ‡§ï‡•á ‡§Ö‡§Ç‡§¶‡§∞ ‡§π‡•Å‡§è\n",
      "Perplexity: 1.8685845136642456\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§™‡•Ç‡§õ‡§æ, '‡§¨‡•Ä‡§∞‡§¨‡§≤, ‡§Ø‡§¶‡§ø ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§™‡§æ‡§∏ ‡§§‡•Ä‡§® ‡§∏‡•á‡§¨ ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§§‡•Å‡§Æ‡•ç‡§π‡•á‡§Ç ‡§Æ‡•Å‡§ù‡•á ‡§è‡§ï ‡§¶‡•á‡§®‡§æ ‡§π‡•à, ‡§§‡•ã ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§™‡§æ‡§∏ ‡§ï‡§ø‡§§‡§®‡•á ‡§∏‡•á‡§¨ ‡§¨‡§ö‡•á‡§Ç‡§ó‡•á?' ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡§ø‡§Ø‡§æ, '‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú, ‡§Æ‡•á‡§∞‡•á ‡§™‡§æ‡§∏ ‡§§‡•Ä‡§® ‡§∏‡•á‡§¨ ‡§•‡•á, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Ü‡§™‡§®‡•á ‡§ï‡§π‡§æ ‡§ï‡§ø ‡§Æ‡•Å‡§ù‡•á ‡§è‡§ï ‡§¶‡•á‡§®‡§æ ‡§π‡•à, ‡§á‡§∏‡§ï‡§æ ‡§Æ‡§§‡§≤‡§¨ ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•á ‡§™‡§æ‡§∏ ‡§è‡§ï ‡§î‡§∞ ‡§Æ‡•á‡§∞‡•á ‡§™‡§æ‡§∏ ‡§¶‡•ã ‡§¨‡§ö‡•á‡§Ç‡§ó‡•á‡•§' ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§æ?\n",
      "Reference Answer: ‡§Ø‡§¶‡§ø ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§™‡§æ‡§∏ ‡§§‡•Ä‡§® ‡§∏‡•á‡§¨ ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§§‡•Å‡§Æ‡•ç‡§π‡•á‡§Ç ‡§Æ‡•Å‡§ù‡•á ‡§è‡§ï ‡§¶‡•á‡§®‡§æ ‡§π‡•à, ‡§§‡•ã ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§™‡§æ‡§∏ ‡§ï‡§ø‡§§‡§®‡•á ‡§∏‡•á‡§¨ ‡§¨‡§ö‡•á‡§Ç‡§ó‡•á?\n",
      "Model Answer: ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§æ?  Akbar ne Birbal se poochha, 'Birbal, agar tumhare paas teen sev bhi hai aur tumhein main ek dena hai, to tumhare paas kitne sev bachenge?' (Akbar asked Birbal, 'If you have three servants and I give one to you, how many servants will you be left with?')\n",
      "Perplexity: 2.132237434387207\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§è‡§ï ‡§¶‡§ø‡§® ‡§∞‡§æ‡§ú‡§æ ‡§ï‡•É‡§∑‡•ç‡§£‡§¶‡•á‡§µ ‡§∞‡§æ‡§Ø ‡§®‡•á ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§∏‡•á ‡§ï‡§π‡§æ ‡§ï‡§ø ‡§µ‡•á ‡§è‡§ï ‡§ê‡§∏‡•Ä ‡§ï‡§µ‡§ø‡§§‡§æ ‡§≤‡§ø‡§ñ‡•á‡§Ç ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§ï‡•á‡§µ‡§≤ ‡§§‡•Ä‡§® ‡§™‡§Ç‡§ï‡•ç‡§§‡§ø‡§Ø‡§æ‡§Å ‡§π‡•ã‡§Ç, ‡§≤‡•á‡§ï‡§ø‡§® ‡§â‡§∏‡§Æ‡•á‡§Ç ‡§ó‡§π‡§∞‡•Ä ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§®‡•Ä ‡§π‡•ã‡•§ ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§§‡•Å‡§∞‡§Ç‡§§ ‡§è‡§ï ‡§ï‡§µ‡§ø‡§§‡§æ ‡§¨‡§®‡§æ‡§à ‡§î‡§∞ ‡§∞‡§æ‡§ú‡§æ ‡§ï‡•ã ‡§∏‡•Å‡§®‡§æ‡§à‡•§ ‡§∞‡§æ‡§ú‡§æ ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂ ‡§π‡•Å‡§è‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§∞‡§æ‡§ú‡§æ ‡§®‡•á ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§≤‡§ø‡§ñ‡§®‡•á ‡§ï‡•ã ‡§ï‡§π‡§æ?\n",
      "Reference Answer: ‡§§‡•Ä‡§® ‡§™‡§Ç‡§ï‡•ç‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§µ‡§æ‡§≤‡•Ä ‡§ó‡§π‡§∞‡•Ä ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§®‡•Ä ‡§ï‡•Ä ‡§ï‡§µ‡§ø‡§§‡§æ\n",
      "Model Answer: ‡§∞‡§æ‡§ú‡§æ ‡§®‡•á ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§∏‡•á ‡§ï‡§π‡§æ ‡§ï‡§ø ‡§µ‡•á ‡§è‡§ï ‡§ê‡§∏‡•Ä ‡§ï‡§µ‡§ø\n",
      "Perplexity: 2.437075614929199\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§™‡•Ç‡§õ‡§æ ‡§ï‡§ø ‡§∏‡§Ç‡§∏‡§æ‡§∞ ‡§ï‡•Ä ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡§ø‡§Ø‡§æ, '‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú, ‡§™‡•ç‡§∞‡•á‡§Æ ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø ‡§π‡•à ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π ‡§∏‡§≠‡•Ä ‡§ï‡•ã ‡§ú‡•ã‡§°‡§º ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§' ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§∏‡§Ç‡§∏‡§æ‡§∞ ‡§ï‡•Ä ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?\n",
      "Reference Answer: ‡§™‡•ç‡§∞‡•á‡§Æ\n",
      "Model Answer: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§∏‡§Ç‡§∏‡§æ‡§∞ ‡§ï‡•Ä ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?  ‡§Ö‡§®‡•Å‡§§‡•ç‡§§‡§∞: ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•á, ‡§∏‡§Ç‡§∏‡§æ‡§∞ ‡§ï‡•Ä ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø ‡§™‡•ç‡§∞‡•á‡§Æ ‡§π‡•à, ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π ‡§∏‡§≠‡•Ä ‡§ï‡•ã ‡§ú‡•ã‡§°‡§º ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§\n",
      "Perplexity: 1.9074651002883911\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§è‡§ï ‡§¶‡§ø‡§® ‡§¨‡§æ‡§ú‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Ç‡§Æ ‡§∞‡§π‡•á ‡§•‡•á, ‡§ú‡§¨ ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¶‡•á‡§ñ‡§æ ‡§ï‡§ø ‡§è‡§ï ‡§Ü‡§¶‡§Æ‡•Ä ‡§ù‡•Ç‡§† ‡§¨‡•ã‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à‡•§ ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§â‡§∏ ‡§Ü‡§¶‡§Æ‡•Ä ‡§∏‡•á ‡§ï‡§π‡§æ, '‡§∏‡§§‡•ç‡§Ø ‡§¨‡•ã‡§≤‡§®‡§æ ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§®‡•à‡§§‡§ø‡§ï‡§§‡§æ ‡§π‡•à‡•§' ‡§Ü‡§¶‡§Æ‡•Ä ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§ó‡§≤‡§§‡•Ä ‡§ï‡§æ ‡§è‡§π‡§∏‡§æ‡§∏ ‡§π‡•Å‡§Ü ‡§î‡§∞ ‡§â‡§∏‡§®‡•á ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§∏‡•á ‡§Æ‡§æ‡§´‡•Ä ‡§Æ‡§æ‡§Å‡§ó‡•Ä‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§Ü‡§¶‡§Æ‡•Ä ‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§π‡§æ?\n",
      "Reference Answer: ‡§∏‡§§‡•ç‡§Ø ‡§¨‡•ã‡§≤‡§®‡§æ ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§®‡•à‡§§‡§ø‡§ï‡§§‡§æ ‡§π‡•à\n",
      "Model Answer: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§Ü‡§¶‡§Æ‡•Ä ‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§π‡§æ?  Tenaliraman ne usse kahaa, \"‡§∏‡§§‡•ç‡§Ø ‡§¨‡•ã‡§≤‡§®‡§æ ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§®‡•à‡§§‡§ø‡§ï‡§§‡§æ ‡§π‡•à, ‡§Ö‡§§‡•É‡§™‡•ç‡§§ ‡§∞‡§π‡§ø‡§Ø‡•á‡•§\" (Tenaliraman told him, \"Telling the truth is the greatest virtue, be content.\")\n",
      "Perplexity: 2.278646945953369\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§ï‡§π‡§æ ‡§ï‡§ø ‡§µ‡•á ‡§è‡§ï ‡§ê‡§∏‡§æ ‡§§‡§∞‡•Ä‡§ï‡§æ ‡§¨‡§§‡§æ‡§è‡§Ç ‡§ú‡§ø‡§∏‡§∏‡•á ‡§∏‡§≠‡•Ä ‡§≤‡•ã‡§ó ‡§ñ‡•Å‡§∂ ‡§π‡•ã ‡§∏‡§ï‡•á‡§Ç‡•§ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡§ø‡§Ø‡§æ, '‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú, ‡§∏‡§¨‡§ï‡•ã ‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§î‡§∞ ‡§∏‡§Æ‡§æ‡§®‡§§‡§æ ‡§¶‡•Ä‡§ú‡§ø‡§è, ‡§§‡§≠‡•Ä ‡§∏‡§≠‡•Ä ‡§≤‡•ã‡§ó ‡§ñ‡•Å‡§∂ ‡§π‡•ã ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§' ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§Ö‡§ï‡§¨‡§∞ ‡§ï‡•ã ‡§ï‡•ç‡§Ø‡§æ ‡§§‡§∞‡•Ä‡§ï‡§æ ‡§¨‡§§‡§æ‡§Ø‡§æ?\n",
      "Reference Answer: ‡§∏‡§¨‡§ï‡•ã ‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§î‡§∞ ‡§∏‡§Æ‡§æ‡§®‡§§‡§æ ‡§¶‡•á‡§®‡§æ\n",
      "Model Answer: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§Ö‡§ï‡§¨‡§∞ ‡§ï‡•ã ‡§ï‡•ç‡§Ø‡§æ ‡§§‡§∞‡•Ä‡§ï‡§æ ‡§¨‡§§‡§æ‡§Ø‡§æ?  ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§Ö‡§ï‡§¨‡§∞ ‡§ï‡•ã ‡§â‡§®‡§ï‡•á ‡§∏‡§¨‡§ï‡•ã ‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§î‡§∞ ‡§∏‡§Æ‡§æ‡§®‡§§‡§æ ‡§¶‡•á‡§®‡•á ‡§ï‡•á ‡§§‡§∞‡•Ä‡§ï‡•á ‡§¨‡§§‡§æ‡§Ø‡§æ ‡§•‡§æ, ‡§úisse ‡§∏‡§≠‡•Ä ‡§≤‡•ã‡§ó ‡§ñ‡•Å‡§∂ ‡§π‡•ã ‡§∏‡§ï‡•á‡§Ç‡§ó‡•á‡•§ ‡§á‡§∏ ‡§§\n",
      "Perplexity: 2.1649436950683594\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§Ö‡§™‡§®‡•á ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§ï‡•ã ‡§è‡§ï ‡§Ö‡§®‡•ã‡§ñ‡•Ä ‡§ò‡§°‡§º‡•Ä ‡§¶‡•Ä ‡§ú‡•ã ‡§π‡§∞ ‡§ò‡§Ç‡§ü‡•á ‡§Ö‡§≤‡§ó-‡§Ö‡§≤‡§ó ‡§∞‡§Ç‡§ó ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡§§‡•Ä ‡§•‡•Ä‡•§ ‡§â‡§∏‡§ï‡•á ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§ï‡•ã ‡§Ø‡§π ‡§ò‡§°‡§º‡•Ä ‡§¨‡§π‡•Å‡§§ ‡§™‡§∏‡§Ç‡§¶ ‡§Ü‡§à ‡§î‡§∞ ‡§â‡§∏‡§®‡•á ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§ï‡•ã ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶ ‡§¶‡§ø‡§Ø‡§æ‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§Ö‡§™‡§®‡•á ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§ï‡•ã ‡§ï‡•ç‡§Ø‡§æ ‡§¶‡§ø‡§Ø‡§æ?\n",
      "Reference Answer: ‡§Ö‡§®‡•ã‡§ñ‡•Ä ‡§ò‡§°‡§º‡•Ä\n",
      "Model Answer: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§Ö‡§™‡§®‡•á ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§ï‡•ã ‡§ï‡•ç‡§Ø‡§æ ‡§¶‡§ø‡§Ø‡§æ?  ‡§ú‡§µ‡§æ‡§¨: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§Ö‡§™‡§®‡•á ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§ï‡•ã ‡§è‡§ï ‡§Ö‡§®‡•ã‡§ñ‡•Ä ‡§ò‡§°‡§º‡•Ä ‡§¶‡•Ä ‡§ú‡•ã ‡§π‡§∞ ‡§ò‡§Ç‡§ü‡•á ‡§Ö‡§≤‡§ó-‡§Ö‡§≤‡§ó ‡§∞‡§Ç‡§ó ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡§§‡•Ä ‡§•‡•Ä‡•§\n",
      "Perplexity: 2.0129036903381348\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§ï‡§π‡§æ ‡§ï‡§ø ‡§µ‡•á ‡§è‡§ï ‡§ê‡§∏‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•Ç‡§õ‡•á‡§Ç ‡§ú‡§ø‡§∏‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞ ‡§ï‡•ã‡§à ‡§® ‡§¶‡•á ‡§∏‡§ï‡•á‡•§ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§™‡•Ç‡§õ‡§æ, '‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú, ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§¨‡§§‡§æ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§á‡§∏ ‡§∏‡§Æ‡§Ø ‡§Ü‡§™‡§ï‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ö‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à?' ‡§Ö‡§ï‡§¨‡§∞ ‡§Æ‡•Å‡§∏‡•ç‡§ï‡•Å‡§∞‡§æ ‡§¶‡§ø‡§è ‡§î‡§∞ ‡§¨‡•ã‡§≤‡•á, '‡§¨‡•Ä‡§∞‡§¨‡§≤, ‡§§‡•Å‡§Æ‡§®‡•á ‡§Æ‡•Å‡§ù‡•á ‡§∏‡•ã‡§ö‡§®‡•á ‡§™‡§∞ ‡§Æ‡§ú‡§¨‡•Ç‡§∞ ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ‡•§' ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§Ö‡§ï‡§¨‡§∞ ‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§æ?\n",
      "Reference Answer: ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§¨‡§§‡§æ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§á‡§∏ ‡§∏‡§Æ‡§Ø ‡§Ü‡§™‡§ï‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ö‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à?\n",
      "Model Answer: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§Ö‡§ï‡§¨‡§∞ ‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§æ?  ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§Ö‡§ï‡§¨‡§∞ ‡§∏‡•á '‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™‡§ï‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ö‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à?' ‡§™‡•Ç‡§õ‡§æ.\n",
      "Perplexity: 2.2544219493865967\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§Ö‡§™‡§®‡•á ‡§∞‡§æ‡§ú‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§≠‡•ã‡§ú ‡§ï‡§æ ‡§Ü‡§Ø‡•ã‡§ú‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§π‡§∞ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§∏‡•ç‡§µ‡§æ‡§¶‡§ø‡§∑‡•ç‡§ü ‡§µ‡•ç‡§Ø‡§Ç‡§ú‡§® ‡§™‡§∞‡•ã‡§∏‡•á‡•§ ‡§∞‡§æ‡§ú‡§æ ‡§®‡•á ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§ï‡•Ä ‡§™‡•ç‡§∞‡§∂‡§Ç‡§∏‡§æ ‡§ï‡•Ä ‡§î‡§∞ ‡§ï‡§π‡§æ ‡§ï‡§ø ‡§Ø‡§π ‡§â‡§®‡§ï‡•á ‡§ú‡•Ä‡§µ‡§® ‡§ï‡§æ ‡§∏‡§¨‡§∏‡•á ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§≠‡•ã‡§ú ‡§•‡§æ‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§∞‡§æ‡§ú‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§Ø‡•ã‡§ú‡§® ‡§ï‡§ø‡§Ø‡§æ?\n",
      "Reference Answer: ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§≠‡•ã‡§ú\n",
      "Model Answer: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§∞‡§æ‡§ú‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§Ø‡•ã‡§ú‡§® ‡§ï‡§ø‡§Ø‡§æ?  Tenaliraman ‡§®‡•á ‡§∞‡§æ‡§ú‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§≠‡•ã‡§ú ‡§ï‡§æ ‡§Ü‡§Ø‡•ã‡§ú‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§π‡§∞ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§∏‡•ç‡§µ‡§æ‡§¶‡§ø‡§∑‡•ç‡§ü ‡§µ‡•ç‡§Ø‡§Ç‡§ú‡§® ‡§™‡§∞‡•ã‡§∏‡•á‡•§ (\n",
      "Perplexity: 2.0333378314971924\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§Ö‡§ï‡§¨‡§∞ ‡§®‡•á ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§∏‡•á ‡§™‡•Ç‡§õ‡§æ ‡§ï‡§ø ‡§∏‡§¨‡§∏‡•á ‡§ï‡•Ä‡§Æ‡§§‡•Ä ‡§µ‡§∏‡•ç‡§§‡•Å ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§®‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡§ø‡§Ø‡§æ, '‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú, ‡§∏‡§¨‡§∏‡•á ‡§ï‡•Ä‡§Æ‡§§‡•Ä ‡§µ‡§∏‡•ç‡§§‡•Å ‡§∏‡§Æ‡§Ø ‡§π‡•à ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π ‡§ï‡§≠‡•Ä ‡§µ‡§æ‡§™‡§∏ ‡§®‡§π‡•Ä‡§Ç ‡§Ü‡§§‡§æ‡•§' ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§∏‡§¨‡§∏‡•á ‡§ï‡•Ä‡§Æ‡§§‡•Ä ‡§µ‡§∏‡•ç‡§§‡•Å ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?\n",
      "Reference Answer: ‡§∏‡§Æ‡§Ø\n",
      "Model Answer: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§∏‡§¨‡§∏‡•á ‡§ï‡•Ä‡§Æ‡§§‡•Ä ‡§µ‡§∏‡•ç‡§§‡•Å ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?  ‡§Ö‡§®‡•Å‡§§‡•ç‡§§‡§∞: ‡§¨‡•Ä‡§∞‡§¨‡§≤ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞, ‡§∏‡§¨‡§∏‡•á ‡§ï‡•Ä‡§Æ‡§§‡•Ä ‡§µ‡§∏‡•ç‡§§‡•Å ‡§∏‡§Æ‡§Ø ‡§π‡•à, ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π ‡§ï‡§≠‡•Ä ‡§µ‡§æ‡§™‡§∏ ‡§®‡§π‡•Ä‡§Ç ‡§Ü‡§§‡§æ‡•§\n",
      "Perplexity: 2.029245376586914\n",
      "---\n",
      "Question: ‡§®‡•Ä‡§ö‡•á ‡§¶‡•Ä ‡§ó‡§à ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡§ï‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç: ‡§è‡§ï ‡§¶‡§ø‡§® ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§¶‡•á‡§ñ‡§æ ‡§ï‡§ø ‡§è‡§ï ‡§ó‡§∞‡•Ä‡§¨ ‡§Ü‡§¶‡§Æ‡•Ä ‡§≠‡•Ç‡§ñ‡§æ ‡§π‡•à‡•§ ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§â‡§∏ ‡§Ü‡§¶‡§Æ‡•Ä ‡§ï‡•ã ‡§≠‡•ã‡§ú‡§® ‡§ï‡§∞‡§æ‡§Ø‡§æ ‡§î‡§∞ ‡§â‡§∏‡•á ‡§Ö‡§™‡§®‡•Ä ‡§ï‡•Å‡§õ ‡§ß‡§®‡§∞‡§æ‡§∂‡§ø ‡§≠‡•Ä ‡§¶‡•Ä‡•§ ‡§µ‡§π ‡§Ü‡§¶‡§Æ‡•Ä ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§ï‡§æ ‡§Ü‡§≠‡§æ‡§∞‡•Ä ‡§π‡•ã ‡§ó‡§Ø‡§æ ‡§î‡§∞ ‡§â‡§∏‡§®‡•á ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§ï‡•ã ‡§Ü‡§∂‡•Ä‡§∞‡•ç‡§µ‡§æ‡§¶ ‡§¶‡§ø‡§Ø‡§æ‡•§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§â‡§∏ ‡§ó‡§∞‡•Ä‡§¨ ‡§Ü‡§¶‡§Æ‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§ø‡§Ø‡§æ?\n",
      "Reference Answer: ‡§≠‡•ã‡§ú‡§® ‡§ï‡§∞‡§æ‡§Ø‡§æ ‡§î‡§∞ ‡§ß‡§®‡§∞‡§æ‡§∂‡§ø ‡§¶‡•Ä\n",
      "Model Answer: ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§â‡§∏ ‡§ó‡§∞‡•Ä‡§¨ ‡§Ü‡§¶‡§Æ‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§ø‡§Ø‡§æ?  ‡§§‡•á‡§®‡§æ‡§≤‡•Ä‡§∞‡§æ‡§Æ ‡§®‡•á ‡§ó‡§∞‡•Ä‡§¨ ‡§Ü‡§¶‡§Æ‡•Ä ‡§ï‡•ã ‡§≠‡•ã‡§ú‡§® ‡§¶‡•á‡§ñ‡§æ ‡§î‡§∞ ‡§â‡§∏‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§™‡§®‡•Ä ‡§ï‡•Å‡§õ ‡§ß‡§®‡§∞‡§æ‡§∂‡§ø ‡§≠‡•Ä ‡§¶‡•Ä‡•§\n",
      "Perplexity: 2.1496379375457764\n",
      "---\n",
      "Overall Perplexity Score: 2.120552660869667\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# Assuming model and tokenizer are already loaded\n",
    "# model, tokenizer = FastLanguageModel.from_pretrained(...)\n",
    "\n",
    "def get_model_response(question):\n",
    "    prompt = f\"<s>[INST] {question} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        num_beams=1,\n",
    "        temperature=0.7,\n",
    "        top_p=0.92,\n",
    "        do_sample=True,\n",
    "        use_cache=True\n",
    "    )\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = full_response.split(\"[INST]\")[-1].split(\"[/INST]\")[-1].strip()\n",
    "    \n",
    "    # Extract only the relevant part of the answer\n",
    "    if \"‡§™‡•ç‡§∞‡§∂‡•ç‡§®:\" in response:\n",
    "        response = response.split(\"‡§™‡•ç‡§∞‡§∂‡•ç‡§®:\")[-1].strip()\n",
    "    if \"‡§â‡§§‡•ç‡§§‡§∞:\" in response:\n",
    "        response = response.split(\"‡§â‡§§‡•ç‡§§‡§∞:\")[-1].strip()\n",
    "    \n",
    "    return response\n",
    "\n",
    "def calculate_perplexity(question, answer):\n",
    "    inputs = tokenizer(question + \" \" + answer, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "    return torch.exp(outputs.loss).item()\n",
    "\n",
    "# Load the dataset\n",
    "with open('Hindi_Benchmark_data.json', 'r', encoding='utf-8') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "perplexities = []\n",
    "\n",
    "# Limit to first 20 questions\n",
    "for item in dataset[:20]:\n",
    "    question = item[\"Question\"]\n",
    "    reference_answer = item[\"Answer\"]\n",
    "    \n",
    "    model_answer = get_model_response(question)\n",
    "    \n",
    "    perplexity = calculate_perplexity(question, model_answer)\n",
    "    perplexities.append(perplexity)\n",
    "    \n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Reference Answer: {reference_answer}\")\n",
    "    print(f\"Model Answer: {model_answer}\")\n",
    "    print(f\"Perplexity: {perplexity}\")\n",
    "    print(\"---\")\n",
    "\n",
    "# Calculate the overall perplexity score\n",
    "overall_perplexity = np.exp(np.mean(np.log(perplexities)))\n",
    "\n",
    "print(f\"Overall Perplexity Score: {overall_perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
